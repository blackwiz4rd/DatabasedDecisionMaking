{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN-STK-5000 Project: Credit risk for mortgages - part 3\n",
    "## Deadline 3: October 16\n",
    "## Luca Attanasio, S M Mamun Ar Rashid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can execute the code by running the cell below. \n",
    "Some changes were made to `TestLending.py` and `TestAuxiliary.py` to include fairness and test the fairness of the decision rules.\n",
    "Only one test on the random forest was used for the report, but nerual network can also be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'python.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run TestLending.py 1 # slow with multiple tests, some plots obtained were commented out.\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing fairness on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load fairness.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from TestAuxiliary import *\n",
    "\n",
    "def calculate_proba(X, y):\n",
    "    ef = X.columns[0]\n",
    "    target = 'repaid'\n",
    "    X[target] = y\n",
    "    target_counts = y.value_counts()\n",
    "    ef_vs_target = X[[ef, target]].groupby(ef).sum()\n",
    "    ef_vs_target['tot'] = X[ef].value_counts()\n",
    "    ef_vs_target[target] = ef_vs_target['tot'] - ef_vs_target[target]\n",
    "    # y = 0 good loan\n",
    "    ef_vs_target['prob'] = ef_vs_target[target]/ef_vs_target['tot'] # P(a|y=0,z)\n",
    "    # ef_vs_target.drop('prob',axis=1).plot.bar()\n",
    "    # plt.show()\n",
    "    # deviation from the good loans probability\n",
    "    ef_vs_target['deviation'] = np.abs(ef_vs_target['prob']-target_counts[0]/X.shape[0])\n",
    "    # if ef == \"age\":\n",
    "    #     plt.plot(ef_vs_target.index, ef_vs_target['prob'])\n",
    "    #     plt.show()\n",
    "\n",
    "    return ef_vs_target\n",
    "\n",
    "def test_fairness(X, y):\n",
    "    y = y - 1 # 1->0 good loan, 2->1 bad loan\n",
    "    target_counts = y.value_counts()\n",
    "    print(\"target counts \", target_counts)\n",
    "    print(\"total\", X.shape[0])\n",
    "\n",
    "    all_deviations = []\n",
    "    encoded_features = X.columns\n",
    "    for ef in encoded_features:\n",
    "        ef_vs_target = calculate_proba(X[[ef]], y)\n",
    "        all_deviations.append(ef_vs_target['deviation'])\n",
    "        print(ef_vs_target.to_latex())\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # ax.boxplot(all_deviations)\n",
    "    # ax.set_xticklabels(encoded_features, rotation=90)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(np.unique(X['age']), all_deviations[encoded_features.index('age')])\n",
    "    # plt.show()\n",
    "\n",
    "    print(y.value_counts())\n",
    "\n",
    "def main():\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    X, encoded_features, target = dataset_setup()\n",
    "\n",
    "    print(encoded_features)\n",
    "\n",
    "    test_fairness(X[encoded_features], X[target])\n",
    "\n",
    "    corr = X.corr()\n",
    "    sns.heatmap(corr[corr>0.6])\n",
    "    plt.show()\n",
    "\n",
    "    # with pm.Model() as logistic_model:\n",
    "    #     str_encoded_features = ''\n",
    "    #     # for ef in encoded_features:\n",
    "    #         # str_encoded_features += ef + ' + '\n",
    "    #     # str_encoded_features = str_encoded_features[:-2]\n",
    "    #     str_encoded_features = 'duration + amount + installment + age'\n",
    "    #     print(str_encoded_features)\n",
    "    #     pm.glm.GLM.from_formula(target + ' ~ ' + str_encoded_features, X, family = pm.glm.families.Binomial())\n",
    "    #     trace = pm.sample(500, tune = 1000, init = 'adapt_diag')\n",
    "    #\n",
    "    # az.plot_trace(trace);\n",
    "\n",
    "    # #Using Pearson Correlation\n",
    "    # # plt.figure(figsize=(12,10))\n",
    "    # # cor = X[encoded_features].corr()\n",
    "    # # cor = cor[cor>0.2]\n",
    "    # # sns.heatmap(cor, cmap=plt.cm.Reds)\n",
    "    # # plt.show()\n",
    "    # #\n",
    "    # # sns.distplot(X['age'])\n",
    "    # # plt.show()\n",
    "    # #\n",
    "    # # sns.jointplot(x=X[\"amount\"], y=X[\"duration\"]);\n",
    "    # # plt.show()\n",
    "    # #\n",
    "    # # sns.pairplot(X[[\"amount\", \"duration\"]])\n",
    "    # # plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to the `project_banker.py` are in the utility function, to include fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load project_banker.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# model for fitting dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# select best model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class ProjectBanker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'forest'\n",
    "        # best values\n",
    "        # set one at a time to -1 for testing the best value with cv!\n",
    "        # self.best_max_depth = -1\n",
    "        self.best_max_depth = 10\n",
    "        # self.best_max_features = None\n",
    "        self.best_max_features = 20\n",
    "\n",
    "    def preprocessing(self, X, fit=False):\n",
    "        X_temp = X.copy()\n",
    "\n",
    "        if fit:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            X_some_features = self.scaler.fit_transform(X_temp)\n",
    "        else:\n",
    "            self.scaler.transform(X_temp)\n",
    "\n",
    "        return X_temp\n",
    "\n",
    "    # Fit the model to the data.  You can use any model you like to do\n",
    "    # the fit, however you should be able to predict all class\n",
    "    # probabilities\n",
    "    \"\"\"\n",
    "    This function uses a random forest classifier to predict new probabilities\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        if self.best_max_depth == -1 and self.best_max_features == -1:\n",
    "            X_scaled = self.preprocessing(X)\n",
    "        else:\n",
    "            X_scaled = self.preprocessing(X,fit=True)\n",
    "\n",
    "        self.clf = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=0,\n",
    "            max_depth=self.best_max_depth,\n",
    "            max_features=self.best_max_features,\n",
    "            class_weight=\"balanced\"\n",
    "        ) # storing classifier\n",
    "        self.clf.fit(X_scaled, y)\n",
    "        print(\"training score \", self.clf.score(X_scaled, y))\n",
    "        # print(\"feature_importances_\", self.clf.feature_importances_)\n",
    "\n",
    "    \"\"\"\n",
    "    Function invoked once to get the best max depth of the tree for\n",
    "    the test set\n",
    "    \"\"\"\n",
    "    def set_best_max_depth(self, X, y):\n",
    "        if self.best_max_depth == -1:\n",
    "            X_scaled = self.preprocessing(X, fit=True)\n",
    "            depths = range(5,20)\n",
    "            untrained_models = [RandomForestClassifier(n_estimators=100, random_state=0, max_depth=d, max_features=self.best_max_features, class_weight=\"balanced\") for d in depths]\n",
    "            fold_scores = [cross_val_score(estimator=m, X=X_scaled, y=y, cv=5) for m in untrained_models]\n",
    "            mean_xv_scores = [s.mean() for s in fold_scores]\n",
    "            print(\"fold: \", fold_scores, len(fold_scores), np.asarray(mean_xv_scores).argmax())\n",
    "            self.best_max_depth = depths[np.asarray(mean_xv_scores).argmax()]\n",
    "            print(\"best_max_depth: \", self.best_max_depth)\n",
    "\n",
    "    \"\"\"\n",
    "    Function invoked to evaluate feature importance\n",
    "    \"\"\"\n",
    "    def set_best_max_features(self, X, y):\n",
    "        if self.best_max_features == -1:\n",
    "            X_scaled = self.preprocessing(X, fit=True)\n",
    "            features = range(20,40,5)\n",
    "            untrained_models = [RandomForestClassifier(n_estimators=100, random_state=0, max_depth=self.best_max_depth, max_features=f, class_weight=\"balanced\") for f in features]\n",
    "            fold_scores = [cross_val_score(estimator=m, X=X_scaled, y=y, cv=5) for m in untrained_models]\n",
    "            mean_xv_scores = [s.mean() for s in fold_scores]\n",
    "            self.best_max_features = features[np.asarray(mean_xv_scores).argmax()]\n",
    "            print(\"best_max_features: \", self.best_max_features)\n",
    "\n",
    "    \"\"\"\n",
    "    Function to test the accuracy of the classifier\n",
    "    \"\"\"\n",
    "    def test_accuracy(self, X, y):\n",
    "        X_scaled = self.preprocessing(X)\n",
    "        return self.clf.score(X_scaled, y)\n",
    "\n",
    "    # set the interest rate\n",
    "    \"\"\"\n",
    "    This function stores the interest rate within the function\n",
    "    \"\"\"\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        return\n",
    "\n",
    "    # Predict the probability of failure for a specific person with data x\n",
    "    \"\"\"\n",
    "    This function predicts the probability of failure (being a bad loan),\n",
    "    given the data to predict for. It is necessary to cast the input\n",
    "    to numpy since it is a Series.\n",
    "    In case of single sample we also need to reshape it.\n",
    "    \"\"\"\n",
    "    def predict_proba(self, x):\n",
    "        x_reshaped = np.reshape(x.to_numpy(), (1, -1))\n",
    "        x_scaled = self.preprocessing(x_reshaped)\n",
    "        prediction = self.clf.predict_proba(x_scaled)\n",
    "        return prediction[0][1]\n",
    "\n",
    "    # The expected utility of granting the loan or not. Here there are two actions:\n",
    "    # action = 0 do not grant the loan\n",
    "    # action = 1 grant the loan\n",
    "    #\n",
    "    # Make sure that you extract the length_of_loan from the\n",
    "    # 2nd attribute of x. Then the return if the loan is paid off to you is\n",
    "    # amount_of_loan*(1 + rate)^length_of_loan\n",
    "    # The return if the loan is not paid off is -amount_of_loan.\n",
    "    \"\"\"\n",
    "    This function calculates the expected utility.\n",
    "    The expected utility if the action is to grant the loan is given by\n",
    "    the formula:\n",
    "    amount_of_loan*(1 + self.rate)^length_of_loan * (1-self.predict_proba(x)) +\n",
    "    -amount_of_loan * self.predict_proba(x)\n",
    "    The expected utility if the action is not to grant anything is: 0\n",
    "    This is true because we don't loose or get anything.\n",
    "    \"\"\"\n",
    "    def expected_utility(self, x, action):\n",
    "        amount_of_loan = x['amount']\n",
    "        length_of_loan = x['duration']\n",
    "        if action == 1:\n",
    "            proba = self.predict_proba(x)\n",
    "            gain = amount_of_loan * (pow(1 + self.rate, length_of_loan)) * (1 - proba)\n",
    "            loss = amount_of_loan * proba\n",
    "            return gain - loss\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def expected_fairness(self, action, sensitive):\n",
    "        p_good = np.array([0.713985, 0.428571]) # from whole dataset\n",
    "        p_bad = np.ones(p_good.size) - p_good\n",
    "        # good if action == 1 == grant\n",
    "        p = p_good if action == 1 else p_bad\n",
    "        return p[sensitive]\n",
    "\n",
    "    # Return the best action. This is normally the one that maximises expected utility.\n",
    "    # However, you are allowed to deviate from this if you can justify the reason.\n",
    "    \"\"\"\n",
    "    This function returns the best action such that the expected utility is\n",
    "    maximized\n",
    "    \"\"\"\n",
    "    def get_best_action(self, x, lam=0):\n",
    "        actions = [0, 1]\n",
    "        sensitive = x['credit history_A31']\n",
    "\n",
    "        # print(\"a=0 grant, not grant\", (1-lam)*self.expected_utility(x, actions[0]), lam*self.expected_fairness(actions[0], sensitive))\n",
    "        # print(\"a=1 grant, not grant\", (1-lam)*self.expected_utility(x, actions[1]), lam*self.expected_fairness(actions[1], sensitive))\n",
    "\n",
    "        utility_0 = (1-lam)*self.expected_utility(x, actions[0]) - lam*self.expected_fairness(actions[0], sensitive)\n",
    "        utility_1 = (1-lam)*self.expected_utility(x, actions[1]) - lam*self.expected_fairness(actions[1], sensitive)\n",
    "        if utility_1 > utility_0:\n",
    "            return actions[1]\n",
    "\n",
    "        return actions[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to the `nn_banker.py` are in the utility function, to include fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load nn_banker.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as npr\n",
    "# model for fitting dataset\n",
    "# implement a nn here with keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.utils import class_weight # assign a class weight\n",
    "# feature selection\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "class ProjectBanker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'nn'\n",
    "        npr.seed(100)\n",
    "\n",
    "    def preprocessing(self, X, fit=False):\n",
    "        # try:\n",
    "        #     X_temp = X.copy()[self.new_features]\n",
    "        # except:\n",
    "        #     X_temp = X.copy()[self.sorting_indexes]\n",
    "        X_temp = X.copy()\n",
    "\n",
    "        if fit:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            X_some_features = self.scaler.fit_transform(X_temp)\n",
    "        else:\n",
    "            self.scaler.transform(X_temp)\n",
    "\n",
    "        return X_temp\n",
    "\n",
    "    # Fit the model to the data.  You can use any model you like to do\n",
    "    # the fit, however you should be able to predict all class\n",
    "    # probabilities\n",
    "    \"\"\"\n",
    "    This function uses a neural network classifier to predict new probabilities\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        y = y - 1 # 0 -> 1 good loan, 1 -> 2 bad loan\n",
    "        # feature selection\n",
    "        # clf = ExtraTreesClassifier(n_estimators=100)\n",
    "        # clf = clf.fit(X, y)\n",
    "        # self.sorting_indexes = np.argsort(clf.feature_importances_)\n",
    "        # self.new_features = [X.columns.values[i] for i in sorting_indexes][28:]\n",
    "\n",
    "        X_scaled = self.preprocessing(X, fit=True)\n",
    "\n",
    "        ## nn with keras\n",
    "        self.model = Sequential([\n",
    "            Dense(64, input_shape=(X_scaled.shape[1],)),\n",
    "            Activation('tanh'),\n",
    "            Dense(32),\n",
    "            Activation('tanh'),\n",
    "            Dense(16),\n",
    "            Activation('tanh'),\n",
    "            Dense(1),\n",
    "            Activation('sigmoid'),\n",
    "        ])\n",
    "\n",
    "        # class_weights = class_weight.compute_class_weight(\n",
    "        #     'balanced',\n",
    "        #     np.unique(y),\n",
    "        #     y\n",
    "        # ) # 0 -> 1 good loan, 1 -> 2 bad loan\n",
    "        class_weights = {0: 700, 1:300}\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        # print(self.model.summary())\n",
    "        # test 150\n",
    "        self.model.fit(X_scaled, y, epochs=20)\n",
    "\n",
    "    def test_accuracy(self, X, y):\n",
    "        y = y - 1\n",
    "        X_scaled = self.preprocessing(X)\n",
    "        test_loss, test_acc = self.model.evaluate(X_scaled, y)\n",
    "        return test_acc\n",
    "\n",
    "    # set the interest rate\n",
    "    \"\"\"\n",
    "    This function stores the interest rate within the function\n",
    "    \"\"\"\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        return\n",
    "\n",
    "    # Predict the probability of failure for a specific person with data x\n",
    "    \"\"\"\n",
    "    This function predicts the probability of failure (being a bad loan),\n",
    "    given the data to predict for. It is necessary to cast the input\n",
    "    to numpy since it is a Series.\n",
    "    In case of single sample we also need to reshape it.\n",
    "    \"\"\"\n",
    "    def predict_proba(self, x):\n",
    "        x_reshaped = np.reshape(x.to_numpy(), (1, -1))\n",
    "        # preprocessing\n",
    "        x_scaled = self.preprocessing(x_reshaped)\n",
    "        prediction = self.model.predict(x_scaled)\n",
    "        return prediction[0][0]\n",
    "\n",
    "    # The expected utility of granting the loan or not. Here there are two actions:\n",
    "    # action = 0 do not grant the loan\n",
    "    # action = 1 grant the loan\n",
    "    #\n",
    "    # Make sure that you extract the length_of_loan from the\n",
    "    # 2nd attribute of x. Then the return if the loan is paid off to you is\n",
    "    # amount_of_loan*(1 + rate)^length_of_loan\n",
    "    # The return if the loan is not paid off is -amount_of_loan.\n",
    "    \"\"\"\n",
    "    This function calculates the expected utility.\n",
    "    The expected utility if the action is to grant the loan is given by\n",
    "    the formula:\n",
    "    amount_of_loan * (pow(1 + self.rate, length_of_loan)) * (1 - self.predict_proba(x)) +\n",
    "    -amount_of_loan * self.predict_proba(x)\n",
    "    The expected utility if the action is not to grant anything is: 0\n",
    "    This is true because we don't loose or get anything.\n",
    "    \"\"\"\n",
    "    def expected_utility(self, x, action):\n",
    "        amount_of_loan = x['amount']\n",
    "        length_of_loan = x['duration']\n",
    "        if action == 1:\n",
    "            proba = self.predict_proba(x)\n",
    "            gain = amount_of_loan * (pow(1 + self.rate, length_of_loan)) * (1 - proba)\n",
    "            loss = amount_of_loan * proba\n",
    "            return gain - loss\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def expected_fairness(self, action, sensitive):\n",
    "        p_good = np.array([0.713985, 0.428571]) # from whole dataset\n",
    "        p_bad = np.ones(p_good.size) - p_good\n",
    "        # good if action == 1 == grant\n",
    "        p = p_good if action == 1 else p_bad\n",
    "        return p[sensitive]\n",
    "\n",
    "    # Return the best action. This is normally the one that maximises expected utility.\n",
    "    # However, you are allowed to deviate from this if you can justify the reason.\n",
    "    \"\"\"\n",
    "    This function returns the best action such that the expected utility is\n",
    "    maximized\n",
    "    \"\"\"\n",
    "    def get_best_action(self, x, lam=0):\n",
    "        actions = [0, 1]\n",
    "        sensitive = x['credit history_A31']\n",
    "        utility_0 = (1-lam)*self.expected_utility(x, actions[0]) - lam*self.expected_fairness(actions[0], sensitive)\n",
    "        utility_1 = (1-lam)*self.expected_utility(x, actions[1]) - lam*self.expected_fairness(actions[1], sensitive)\n",
    "        if utility_1 > utility_0:\n",
    "            return actions[1]\n",
    "\n",
    "        return actions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
