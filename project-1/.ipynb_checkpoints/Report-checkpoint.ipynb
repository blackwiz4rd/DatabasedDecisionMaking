{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN-STK-5000 Project: Credit risk for mortgages - part 1\n",
    "## Deadline 1: September 18\n",
    "## Luca Attanasio, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can execute the code by running the cell below. \n",
    "Some changes were made to `TestLending.py` in order to collect all the utilities from each of the bankers and use boxplots to plot the utility values. Boxplots are not the best idea to plot the utility values since they can be misleading (on different tests one banker may outperform another and viceversa in other situations), but we can feel how well the banker is doing.\n",
    "# WARNING: The code runs really slow with n_tests=100 (so we set the value to n_tests=2 here). For n_tests=100 look at the results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run TestLending.py 2\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots for 100 tests: utility vs strategy\n",
    "The boxplots show the mean, and variance of the resulting utility for each banker.\n",
    "\n",
    "<img src=\"100_tests.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we use five bankers to collect data. In particular:\n",
    "1. deterministic banker: always grant\n",
    "2. deterministic banker: never grant\n",
    "3. random banker\n",
    "4. random forest banker\n",
    "5. neural network banker (not optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's comment on the results obtained and then see the practical implementation. \n",
    "\n",
    "The worst performances are obtained if we always don't grant the loan. This behaviour is expected since the expected utility is always 0 and we have a high interest rate per month: $5\\%$. We are aware that having a much lower interest rate may change the results (e.g. having $0.5\\%$ per month), in that case the best option is probably this one since if we have a classifier with a $70\\%$ accuracy, then if we grant a loan which won't be repaid we loose much more than what we can gain from all the other loans.\n",
    "\n",
    "The second worst performances are those of the random classifier. Randomly choosing to grant or not a loan is not a good idea because we don't take into consideration any data from the input user. On average, half the loans are granted and half are not, but we don't make any assumption on which can be good and which can be bad.\n",
    "\n",
    "The deterministic banker that always grants the loan has surprisingly good performances compared to the random forest banker and the neural network banker. Always granting the loan seems to be a good option, since we will always gain money if the users can pay it back. On this dataset, many users can pay back the loan and this option would increase our gain.\n",
    "\n",
    "The random forest banker has great performances, it outperforms the always grant classifier on most tests but it doesn't have a perfect accuracy on the testing set. The random forest banker is granting the loan most of the times and not granting the loan just in some cases. This is because the classifier isn't super-accurate ($75\\%$ on average on the test set) and the utility function prefers to give the loan even if the classifier tends to avoid giving it (have a look in the code below). This behaviour is the preferred choice, since the utility is higher compared to relying purely on the classifier.\n",
    "\n",
    "The neural network banker can still be improved, not much time was used to develop its model but it can surely be optimized to get the same results or better than the random forest.\n",
    "\n",
    "To improve the accuracy of both the random forest and neural network, the MinMaxScaler was used, in order to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. and 2. deterministic banker\n",
    "The determinisc_banker can be initialized with an action that can be either 0 or 1, respectively the never grant and always grant bankers. Consequently, the action it always chooses is either 0 or 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load deterministic_banker\n",
    "import numpy as np\n",
    "\n",
    "class DeterministicBanker:\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize banker with a given action: 0 don't grant, 1 grant the loan\n",
    "    \"\"\"\n",
    "    def __init__(self, action):\n",
    "        self.name = 'deterministic'\n",
    "        self.action = action\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def expected_utility(self, x, action):\n",
    "        print(\"Expected utility: Not implemented\")\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Always grant or not grant the loan\n",
    "    \"\"\"\n",
    "    def get_best_action(self, x):\n",
    "        return self.action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. random banker\n",
    "The random banker returns a random action between 0 and 1. It may randomly go well, but it is the worst strategy to choose if we want to maximize the total utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load random_banker.py\n",
    "import numpy as np\n",
    "\n",
    "class RandomBanker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'random'\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.data = [X, y]\n",
    "\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        # return\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return 0\n",
    "\n",
    "    def expected_utility(self, x, action):\n",
    "        print(\"Expected utility: Not implemented\")\n",
    "\n",
    "    \"\"\"\n",
    "    The returned action is either to grant (1) or not the loan (0) randomly\n",
    "    \"\"\"\n",
    "    def get_best_action(self, x):\n",
    "        return np.random.choice(2,1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the exected utility\n",
    "Before getting into the code for the random forest and neural network banker we explain the methodology used to get the expected utility.\n",
    "\n",
    "The probability $\\mathbb{P}(\\vec{x})$ of being a bad loan, output of the classifier for a given sample, is used to calculate the expected utility $\\mathbb{U}$ of a sample. In particular the formula used to get the expected utility is the following in case we grant the loan:\n",
    "\\begin{equation}\n",
    "    \\mathbb{E}(U | A) = m \\cdot (1 + r)^n \\cdot (1 - \\mathbb{P}(\\vec{x})) - m \\cdot \\mathbb{P}(\\vec{x})\n",
    "\\end{equation}\n",
    "where $m$ is the amount of the loan, $r$ is the interest rate (per month), $n$ is the lending period (in months) and $A$ is the action of granting the loan.\n",
    "\n",
    "\n",
    "If we don't grant the loan, then the expected utility is null, since we don't gain anything but we also don't risk to loose anything.\n",
    "\\begin{equation}\n",
    "    \\mathbb{E}(U | B) = 0\n",
    "\\end{equation}\n",
    "where $B$ is the action of not granting the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximizing the expected utility\n",
    "In order to evaluate the best action between granting or not granting the loan, we can take the maximum between the expected utility of granting and not granting the loan. The corresponding action is our result.\n",
    "The value of\n",
    "\\begin{equation}\n",
    "    \\max{(\\mathbb{E}(U | A), \\mathbb{E}(U | B))} \n",
    "\\end{equation}\n",
    "is 0 if $\\mathbb{E}(U | A) < 0$ and $\\mathbb{E}(U | A)$ otherwise.\n",
    "The most common action is to grant the loan, because usually\n",
    "\\begin{equation}\n",
    "    m \\cdot (1 + r)^n \\cdot (1 - \\mathbb{P}(\\vec{x})) > m \\cdot \\mathbb{P}(\\vec{x})\n",
    "\\end{equation}\n",
    "\n",
    "##### Comment: Instead of maximizing the utility, another option would be to put a lower or upper threshold on the expected utility. This could avoid granting some loans where we are not sure of the outcome and avoid risking too much on users who require really high loans. We saw that putting a lower threshold on the utility doesn't change the results by much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random forest banker\n",
    "This banker uses a random forest classifier to predict the probability that the given input is a bad loan.\n",
    "To get the best performances out of the classifier, cross fold validation is used against each training set, to select the best value of max depth for the tree. In addition, the random forest was optimizied by setting the $best_max_depth$ and $best_max_features$ using cross-fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load project_banker.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# model for fitting dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# select best model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class ProjectBanker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'forest'\n",
    "        # best values\n",
    "        # set one at a time to None for testing the best value with cv!\n",
    "        # self.best_max_depth = None\n",
    "        self.best_max_depth = 15\n",
    "        # self.best_max_features = None\n",
    "        self.best_max_features = 35\n",
    "\n",
    "    def preprocessing(self, X, fit=False):\n",
    "        X_temp = X.copy()\n",
    "\n",
    "        if fit:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            X_some_features = self.scaler.fit_transform(X_temp)\n",
    "        else:\n",
    "            self.scaler.transform(X_temp)\n",
    "\n",
    "        return X_temp\n",
    "\n",
    "    # Fit the model to the data.  You can use any model you like to do\n",
    "    # the fit, however you should be able to predict all class\n",
    "    # probabilities\n",
    "    \"\"\"\n",
    "    This function uses a random forest classifier to predict new probabilities\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        if self.best_max_depth == None and self.best_max_features == None:\n",
    "            X_scaled = self.preprocessing(X)\n",
    "        else:\n",
    "            X_scaled = self.preprocessing(X,fit=True)\n",
    "\n",
    "        self.clf = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=0,\n",
    "            max_depth=self.best_max_depth,\n",
    "            max_features=self.best_max_features,\n",
    "            class_weight=\"balanced\"\n",
    "        ) # storing classifier\n",
    "        self.clf.fit(X_scaled, y)\n",
    "        print(\"training score \", self.clf.score(X_scaled, y))\n",
    "        # print(\"feature_importances_\", self.clf.feature_importances_)\n",
    "\n",
    "    \"\"\"\n",
    "    Function invoked once to get the best max depth of the tree for\n",
    "    the test set\n",
    "    \"\"\"\n",
    "    def set_best_max_depth(self, X, y):\n",
    "        if self.best_max_depth == None:\n",
    "            X_scaled = self.preprocessing(X, fit=True)\n",
    "            depths = range(5,20)\n",
    "            untrained_models = [RandomForestClassifier(n_estimators=100, random_state=0, max_depth=d, max_features=self.best_max_features, class_weight=\"balanced\") for d in depths]\n",
    "            fold_scores = [cross_val_score(estimator=m, X=X_scaled, y=y, cv=5) for m in untrained_models]\n",
    "            mean_xv_scores = [s.mean() for s in fold_scores]\n",
    "            print(\"fold: \", fold_scores, len(fold_scores), np.asarray(mean_xv_scores).argmax())\n",
    "            self.best_max_depth = depths[np.asarray(mean_xv_scores).argmax()]\n",
    "            print(\"best_max_depth: \", self.best_max_depth)\n",
    "\n",
    "    \"\"\"\n",
    "    Function invoked to evaluate feature importance\n",
    "    \"\"\"\n",
    "    def set_best_max_features(self, X, y):\n",
    "        if self.best_max_features == None:\n",
    "            X_scaled = self.preprocessing(X, fit=True)\n",
    "            features = range(20,40,5)\n",
    "            untrained_models = [RandomForestClassifier(n_estimators=100, random_state=0, max_depth=self.best_max_depth, max_features=f, class_weight=\"balanced\") for f in features]\n",
    "            fold_scores = [cross_val_score(estimator=m, X=X_scaled, y=y, cv=5) for m in untrained_models]\n",
    "            mean_xv_scores = [s.mean() for s in fold_scores]\n",
    "            self.best_max_features = features[np.asarray(mean_xv_scores).argmax()]\n",
    "            print(\"best_max_features: \", self.best_max_features)\n",
    "\n",
    "    \"\"\"\n",
    "    Function to test the accuracy of the classifier\n",
    "    \"\"\"\n",
    "    def test_accuracy(self, X, y):\n",
    "        X_scaled = self.preprocessing(X)\n",
    "        return self.clf.score(X_scaled, y)\n",
    "\n",
    "    # set the interest rate\n",
    "    \"\"\"\n",
    "    This function stores the interest rate within the function\n",
    "    \"\"\"\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        return\n",
    "\n",
    "    # Predict the probability of failure for a specific person with data x\n",
    "    \"\"\"\n",
    "    This function predicts the probability of failure (being a bad loan),\n",
    "    given the data to predict for. It is necessary to cast the input\n",
    "    to numpy since it is a Series.\n",
    "    In case of single sample we also need to reshape it.\n",
    "    \"\"\"\n",
    "    def predict_proba(self, x):\n",
    "        x_reshaped = np.reshape(x.to_numpy(), (1, -1))\n",
    "        x_scaled = self.preprocessing(x_reshaped)\n",
    "        prediction = self.clf.predict_proba(x_scaled)\n",
    "        return prediction[0][1]\n",
    "\n",
    "    # The expected utility of granting the loan or not. Here there are two actions:\n",
    "    # action = 0 do not grant the loan\n",
    "    # action = 1 grant the loan\n",
    "    #\n",
    "    # Make sure that you extract the length_of_loan from the\n",
    "    # 2nd attribute of x. Then the return if the loan is paid off to you is\n",
    "    # amount_of_loan*(1 + rate)^length_of_loan\n",
    "    # The return if the loan is not paid off is -amount_of_loan.\n",
    "    \"\"\"\n",
    "    This function calculates the expected utility.\n",
    "    The expected utility if the action is to grant the loan is given by\n",
    "    the formula:\n",
    "    amount_of_loan*(1 + self.rate)^length_of_loan * (1-self.predict_proba(x)) +\n",
    "    -amount_of_loan * self.predict_proba(x)\n",
    "    The expected utility if the action is not to grant anything is: 0\n",
    "    This is true because we don't loose or get anything.\n",
    "    \"\"\"\n",
    "    def expected_utility(self, x, action):\n",
    "        amount_of_loan = x['amount']\n",
    "        length_of_loan = x['duration']\n",
    "        if action == 1:\n",
    "            proba = self.predict_proba(x)\n",
    "            gain = amount_of_loan * (pow(1 + self.rate, length_of_loan)) * (1 - proba)\n",
    "            loss = amount_of_loan * proba\n",
    "            return gain - loss\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # Return the best action. This is normally the one that maximises expected utility.\n",
    "    # However, you are allowed to deviate from this if you can justify the reason.\n",
    "    \"\"\"\n",
    "    This function returns the best action such that the expected utility is\n",
    "    maximized\n",
    "    \"\"\"\n",
    "    def get_best_action(self, x):\n",
    "        ## better way to calculate utility that allows to defiate from max\n",
    "        ## threshold may be set higher to avoid granting too many loans\n",
    "        actions = [0, 1]\n",
    "        utility_0 = self.expected_utility(x, actions[0])\n",
    "        utility_1 = self.expected_utility(x, actions[1])\n",
    "        # grant about accuracy/100*200 = 150 -> error estimate\n",
    "        # most of the measures are below 20 000\n",
    "        threshold = 500\n",
    "        if utility_1 - utility_0 > threshold:\n",
    "            return actions[1]\n",
    "        return actions[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Neural network banker\n",
    "This banker uses a neural network classifier to predict the probability that the given input is a bad loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load nn_banker.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as npr\n",
    "# model for fitting dataset\n",
    "# implement a nn here with keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "class ProjectBanker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'nn'\n",
    "        npr.seed(100)\n",
    "\n",
    "    def preprocessing(self, X, fit=False):\n",
    "        X_temp = X.copy()\n",
    "        # rescale_features = ['age', 'duration', 'amount']\n",
    "        # X_some_features = X_temp[rescale_features]\n",
    "\n",
    "        if fit:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            X_some_features = self.scaler.fit_transform(X_temp)\n",
    "        else:\n",
    "            self.scaler.transform(X_temp)\n",
    "\n",
    "        # X_temp[rescale_features] = X_some_features\n",
    "        return X_temp\n",
    "\n",
    "    # Fit the model to the data.  You can use any model you like to do\n",
    "    # the fit, however you should be able to predict all class\n",
    "    # probabilities\n",
    "    \"\"\"\n",
    "    This function uses a neural network classifier to predict new probabilities\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        print(X.shape, y.shape)\n",
    "        y = y - 1\n",
    "        X_scaled = self.preprocessing(X, fit=True)\n",
    "\n",
    "        ## nn with keras\n",
    "        self.model = Sequential([\n",
    "            Dense(64, input_shape=(X.shape[1],)),\n",
    "            Activation('relu'),\n",
    "            Dense(32),\n",
    "            Activation('relu'),\n",
    "            Dense(16),\n",
    "            Activation('relu'),\n",
    "            Dense(1),\n",
    "            Activation('sigmoid'),\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "        self.model.fit(X_scaled, y, epochs=7)\n",
    "\n",
    "    def test_accuracy(self, X, y):\n",
    "        y = y - 1\n",
    "        X_scaled = self.preprocessing(X)\n",
    "        test_loss, test_acc = self.model.evaluate(X_scaled, y)\n",
    "        return test_acc\n",
    "\n",
    "    # set the interest rate\n",
    "    \"\"\"\n",
    "    This function stores the interest rate within the function\n",
    "    \"\"\"\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        return\n",
    "\n",
    "    # Predict the probability of failure for a specific person with data x\n",
    "    \"\"\"\n",
    "    This function predicts the probability of failure (being a bad loan),\n",
    "    given the data to predict for. It is necessary to cast the input\n",
    "    to numpy since it is a Series.\n",
    "    In case of single sample we also need to reshape it.\n",
    "    \"\"\"\n",
    "    def predict_proba(self, x):\n",
    "        x_reshaped = np.reshape(x.to_numpy(), (1, -1))\n",
    "        # preprocessing\n",
    "        x_scaled = self.preprocessing(x_reshaped)\n",
    "        prediction = self.model.predict(x_scaled)\n",
    "        return prediction[0][0]\n",
    "\n",
    "    # The expected utility of granting the loan or not. Here there are two actions:\n",
    "    # action = 0 do not grant the loan\n",
    "    # action = 1 grant the loan\n",
    "    #\n",
    "    # Make sure that you extract the length_of_loan from the\n",
    "    # 2nd attribute of x. Then the return if the loan is paid off to you is\n",
    "    # amount_of_loan*(1 + rate)^length_of_loan\n",
    "    # The return if the loan is not paid off is -amount_of_loan.\n",
    "    \"\"\"\n",
    "    This function calculates the expected utility.\n",
    "    The expected utility if the action is to grant the loan is given by\n",
    "    the formula:\n",
    "    amount_of_loan * (pow(1 + self.rate, length_of_loan)) * (1 - self.predict_proba(x)) +\n",
    "    -amount_of_loan * self.predict_proba(x)\n",
    "    The expected utility if the action is not to grant anything is: 0\n",
    "    This is true because we don't loose or get anything.\n",
    "    \"\"\"\n",
    "    def expected_utility(self, x, action):\n",
    "        amount_of_loan = x['amount']\n",
    "        length_of_loan = x['duration']\n",
    "        if action == 1:\n",
    "            proba = self.predict_proba(x)\n",
    "            gain = amount_of_loan * (pow(1 + self.rate, length_of_loan)) * (1 - proba)\n",
    "            loss = amount_of_loan * proba\n",
    "            return gain - loss\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # Return the best action. This is normally the one that maximises expected utility.\n",
    "    # However, you are allowed to deviate from this if you can justify the reason.\n",
    "    \"\"\"\n",
    "    This function returns the best action such that the expected utility is\n",
    "    maximized\n",
    "    \"\"\"\n",
    "    def get_best_action(self, x):\n",
    "        actions = [0, 1]\n",
    "        utility_0 = self.expected_utility(x, actions[0])\n",
    "        utility_1 = self.expected_utility(x, actions[1])\n",
    "        threshold = 500\n",
    "        if utility_1 - utility_0 > threshold:\n",
    "            return actions[1]\n",
    "\n",
    "        return actions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
